{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOOlGz31naK+mU1bPyKxXPl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3reSFh7uEnZ","executionInfo":{"status":"ok","timestamp":1659681479291,"user_tz":300,"elapsed":21236,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}},"outputId":"96a76dc9-67dd-4de5-eace-a909e8ca556c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Reading package lists... Done\n"]}]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"metadata":{"id":"3ci98E6fubtB","executionInfo":{"status":"ok","timestamp":1659681518341,"user_tz":300,"elapsed":6928,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer"],"metadata":{"id":"skc7TXwtukXX","executionInfo":{"status":"ok","timestamp":1659681534125,"user_tz":300,"elapsed":255,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Create sample DataFrame\n","dataframe = spark.createDataFrame([\n","    (0, \"Spark is great\"),\n","    (1, \"We are learning Spark\"),\n","    (2, \"Spark is better than haddop no doubt\")\n","], [\"id\", \"sentence\"])\n","\n","dataframe.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neJN4N8qussv","executionInfo":{"status":"ok","timestamp":1659681868995,"user_tz":300,"elapsed":6246,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}},"outputId":"752f00b2-3e63-420c-88cd-833e8ecab906"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSLh9w6tv8MP","executionInfo":{"status":"ok","timestamp":1659681886155,"user_tz":300,"elapsed":115,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}},"outputId":"a3babe16-4c4f-4cae-959d-87174a2be2fd"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_a168ffb8b442"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Transform and show DataFrame\n","tokenizer_df = tokenizer.transform(dataframe)\n","tokenizer_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMmdR6xCv-_8","executionInfo":{"status":"ok","timestamp":1659681962247,"user_tz":300,"elapsed":1027,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}},"outputId":"1296781d-3796-40a4-9ac2-be46d2ad7b84"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than haddop no doubt|[spark, is, better, than, haddop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"metadata":{"id":"7IaLj7XbwSn3","executionInfo":{"status":"ok","timestamp":1659681977993,"user_tz":300,"elapsed":142,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"metadata":{"id":"meJhi0XTwV0Q","executionInfo":{"status":"ok","timestamp":1659681990536,"user_tz":300,"elapsed":110,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"metadata":{"id":"RP1L7zRtwX9R","executionInfo":{"status":"ok","timestamp":1659682006578,"user_tz":300,"elapsed":139,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Create our Tokenizer\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","\n","#Transform DataFrame\n","tokenizer_df = tokenizer.transform(dataframe)\n","\n","#Select the needed columns and don't truncate results\n","tokenizer_df.withColumn(\"tokens\",count_tokens(col(\"words\"))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtPOpsvzwa2R","executionInfo":{"status":"ok","timestamp":1659682447957,"user_tz":300,"elapsed":999,"user":{"displayName":"Eva Hawkins","userId":"02230375989068476203"}},"outputId":"85e8e499-2c40-48d0-d6bf-f714671e515b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than haddop no doubt|[spark, is, better, than, haddop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]}]}